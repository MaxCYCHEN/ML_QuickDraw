{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/Sketcher.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6H3ATAdp_URp"
   },
   "source": [
    "# Get the Class names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlx6-LFL_jbi"
   },
   "source": [
    "This file contains a subset of the quick draw classes. I choose around 100 classes from the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GL_TdMffD6-"
   },
   "source": [
    "Read the classes names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eP-OxOx5sy0b"
   },
   "outputs": [],
   "source": [
    "f = open(\"categories.txt\",\"r\")\n",
    "# And for reading use\n",
    "classes = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lTE6D3uxtMc5"
   },
   "outputs": [],
   "source": [
    "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5NDfBHVjACAt"
   },
   "source": [
    "# Download the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MC_PUS-fKjH"
   },
   "source": [
    "Loop over the classes and download the currospondent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22DPhL5FtWcQ"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def download():\n",
    "  \n",
    "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
    "  for c in classes:\n",
    "    cls_url = c.replace('_', '%20')\n",
    "    path = base+cls_url+'.npy'\n",
    "    print(path)\n",
    "    urllib.request.urlretrieve(path, 'dataset/'+c+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1754
    },
    "colab_type": "code",
    "id": "O5jF6TXXu-Bu",
    "outputId": "865b0cb8-46a4-4ead-f644-488b00c7d89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/aircraft%20carrier.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ambulance.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/angel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/animal%20migration.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ant.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/arm.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/asparagus.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/backpack.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/banana.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bandage.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/barn.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basket.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bathtub.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beach.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bear.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bee.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/belt.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/binoculars.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/birthday%20cake.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/blackberry.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/blueberry.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/boomerang.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bottlecap.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bowtie.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bracelet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/brain.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broccoli.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bucket.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bulldozer.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bus.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bush.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cactus.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cake.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/calculator.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/calendar.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camouflage.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/campfire.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cannon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/canoe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/carrot.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/castle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cello.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chandelier.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/church.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clarinet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/compass.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/computer.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cooler.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/couch.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cow.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crab.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crayon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crocodile.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crown.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cruise%20ship.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diamond.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dishwasher.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dolphin.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dragon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dresser.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drill.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/duck.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ear.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/elbow.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/elephant.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eraser.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/feather.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fence.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/finger.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fire%20hydrant.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fireplace.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/firetruck.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fish.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flamingo.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flashlight.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flip%20flops.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/floor%20lamp.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flying%20saucer.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/foot.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fork.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frog.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/garden.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/garden%20hose.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/giraffe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/goatee.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/golf%20club.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grass.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/guitar.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hamburger.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hand.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/harp.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hedgehog.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helicopter.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hexagon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hockey%20puck.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hockey%20stick.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/horse.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hospital.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20air%20balloon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20tub.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hourglass.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/house.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/house%20plant.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hurricane.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/jacket.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/jail.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/kangaroo.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/keyboard.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knee.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lantern.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/leaf.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/leg.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lighter.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lighthouse.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lion.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lipstick.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lobster.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mailbox.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/map.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/marker.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/matches.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/megaphone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mermaid.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microwave.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/monkey.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mosquito.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/motorbike.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mouse.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mouth.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mug.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/nail.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/necklace.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/nose.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ocean.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/octagon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/octopus.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/onion.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/oven.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/owl.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paintbrush.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paint%20can.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/palm%20tree.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/panda.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/parachute.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/parrot.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/passport.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/peanut.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pear.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/peas.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/penguin.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/piano.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pickup%20truck.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/picture%20frame.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pig.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pineapple.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pliers.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/police%20car.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pond.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pool.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/popsicle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/postcard.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/potato.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/purse.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rabbit.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/raccoon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rain.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rake.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/remote%20control.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rhinoceros.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/river.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/roller%20coaster.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rollerskates.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sailboat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sandwich.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saxophone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/school%20bus.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scorpion.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sea%20turtle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/see%20saw.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shark.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sheep.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shoe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sink.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/skateboard.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/skull.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/skyscraper.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sleeping%20bag.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snail.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snorkel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snowflake.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snowman.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/soccer%20ball.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/speedboat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spreadsheet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/squiggle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/squirrel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stairs.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/steak.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stereo.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stethoscope.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stitches.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stove.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/strawberry.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/streetlight.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/string%20bean.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/submarine.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/swan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sweater.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/swing%20set.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/teapot.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/teddy-bear.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/telephone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/television.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Eiffel%20Tower.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Great%20Wall%20of%20China.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Mona%20Lisa.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tiger.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toaster.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toilet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toothbrush.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toothpaste.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tornado.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tractor.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/train.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/trombone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/truck.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/trumpet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/underwear.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/van.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/vase.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/violin.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/washing%20machine.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/watermelon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/waterslide.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/whale.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/windmill.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wine%20bottle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wine%20glass.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/yoga.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/zebra.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/zigzag.npy\n"
     ]
    }
   ],
   "source": [
    "download() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEdnbBVXAI-X"
   },
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2FYrPgOKh6t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6o30ipBPAQ5Y"
   },
   "source": [
    "# Load the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBq3GXEKAYuO"
   },
   "source": [
    "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HEIgQNHYQnl"
   },
   "outputs": [],
   "source": [
    "def load_data(root, vfold_ratio_test=0.2, vfold_ratio_val=0.1, max_items_per_class= 4000 ):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "    #initialize variables \n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    #load each data file \n",
    "    for idx, file in enumerate(all_files):\n",
    "        data = np.load(file)\n",
    "        #data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "        class_names.append(class_name)\n",
    "\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    #randomize the dataset \n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    x = x[permutation, :]\n",
    "    y = y[permutation]\n",
    "\n",
    "    #separate into training and testing \n",
    "    vfold_size_t = int(x.shape[0]/100*(vfold_ratio_test*100))\n",
    "    vfold_size_v = int(x.shape[0]/100*((vfold_ratio_val+vfold_ratio_test)*100))\n",
    "\n",
    "    x_test = x[0:vfold_size_t, :]\n",
    "    y_test = y[0:vfold_size_t]\n",
    "    \n",
    "    x_val = x[vfold_size_t:vfold_size_v, :]\n",
    "    y_val = y[vfold_size_t:vfold_size_v]\n",
    "\n",
    "    x_train = x[vfold_size_v:x.shape[0], :]\n",
    "    y_train = y[vfold_size_v:y.shape[0]]\n",
    "    return x_train, y_train, x_test, y_test, x_val, y_val, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_batch(root, vfold_ratio_test=0.2, vfold_ratio_val=0.1, file_batch_size = 2):\n",
    "  \n",
    "    # Get a list of all .npy files in the directory\n",
    "    file_list = glob.glob(os.path.join(root, '*.npy'))\n",
    "    print(file_list)\n",
    "    \n",
    "    # Create a TensorFlow dataset from the file list\n",
    "    file_dataset = tf.data.Dataset.from_tensor_slices(file_list)\n",
    "    print(file_dataset.cardinality().numpy())\n",
    "    print(type(file_dataset.take(1)))\n",
    "    \n",
    "    # Define a function to load and process each file\n",
    "    def load_and_process(file_path):\n",
    "        data = np.load(file_path)\n",
    "        # Perform any necessary processing on the data\n",
    "        #data.reshape(data.shape[0], image_size, image_size, 1).astype('float32')\n",
    "        #data /= 255.0\n",
    "        return data\n",
    "\n",
    "    # Map the file_dataset to the load_and_process function\n",
    "    data_dataset = file_dataset.map(load_and_process)\n",
    "    print(data_dataset.cardinality().numpy())\n",
    "    \n",
    "    # Concatenate the data_dataset into a single combined dataset\n",
    "    combined_dataset = data_dataset.concatenate()\n",
    "    print(combined_dataset.cardinality().numpy())\n",
    "\n",
    "  \n",
    "    \n",
    "    #return x_train, y_train, x_test, y_test, x_val, y_val, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [147]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m class_names\u001b[38;5;241m.\u001b[39mappend(class_name)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     combined_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(combined_dataset\u001b[38;5;241m.\u001b[39mcardinality()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:814\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    738\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4708\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4707\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4708\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4709\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m   4710\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:126\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    123\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    125\u001b[0m         normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 126\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1629\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1631\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1634\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1635\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1638\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1641\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     47\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "file_list = ['dataset_test\\\\aircraft_carrier.npy', 'dataset_test\\\\airplane.npy', 'dataset_test\\\\alarm_clock.npy', 'dataset_test\\\\ambulance.npy', 'dataset_test\\\\angel.npy', 'dataset_test\\\\animal_migration.npy']\n",
    "#file_dataset = tf.data.Dataset.from_tensor_slices(file_list)\n",
    "\n",
    "## Define a function to load and process each file\n",
    "#def load_and_process(file_path):\n",
    "#    #print(\"file_path: \",bytes.decode(file_path.numpy()),type(bytes.decode(file_path.numpy())))\n",
    "#    \n",
    "#    data = np.load(bytes.decode(file_path.numpy()))\n",
    "#    # Perform any necessary processing on the data\n",
    "#    data.reshape(data.shape[0], image_size, image_size, 1).astype('float32')\n",
    "#    data /= 255.0\n",
    "#    return data\n",
    "## Map the file_dataset to the load_and_process function\n",
    "#data_dataset = file_dataset.map(lambda x: tf.py_function(load_and_process, [x], [tf.string]))\n",
    "#print(data_dataset.cardinality().numpy())\n",
    "\n",
    "#initialize variables \n",
    "\n",
    "\n",
    "file_list = glob.glob(os.path.join('dataset', '*.npy'))\n",
    "class_names = []\n",
    "\n",
    "#load each data file \n",
    "for idx, file in enumerate(file_list):\n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    data = np.load(file)\n",
    "    labels = np.full(data.shape[0], idx)\n",
    "    x = np.concatenate((x, data), axis=0)\n",
    "    y = np.append(y, labels)\n",
    "    class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "    class_names.append(class_name)\n",
    "    \n",
    "    if(idx == 0):\n",
    "        combined_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        print(combined_dataset.cardinality().numpy())\n",
    "    else:\n",
    "        s_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        combined_dataset = combined_dataset.concatenate(s_dataset)\n",
    "        print(combined_dataset.cardinality().numpy())\n",
    "\n",
    "print(combined_dataset.cardinality().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\\aircraft_carrier.npy 0\n",
      "(116504, 28, 28, 1) (116504,)\n",
      "tf.Tensor([0 0 0 ... 0 0 0], shape=(116504,), dtype=int8)\n",
      "dataset\\airplane.npy 1\n",
      "(151623, 28, 28, 1) (151623,)\n",
      "tf.Tensor([1 1 1 ... 1 1 1], shape=(151623,), dtype=int8)\n",
      "dataset\\alarm_clock.npy 2\n",
      "(123399, 28, 28, 1) (123399,)\n",
      "tf.Tensor([2 2 2 ... 2 2 2], shape=(123399,), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "# Define the function to load data from a single .npy file\n",
    "def load_data(filename, idx):\n",
    "    data = np.load(filename)\n",
    "    data = data.reshape(data.shape[0], 28, 28, 1).astype('float32')\n",
    "    data /= 255.0\n",
    "    labels = np.full(data.shape[0], idx)\n",
    "    return data, labels\n",
    "\n",
    "# Define the generator function to yield data from multiple files\n",
    "def data_generator(filenames):\n",
    "    idx = 0\n",
    "    for filename in filenames:\n",
    "        print(filename, idx)\n",
    "        data = load_data(filename, idx)\n",
    "        idx += 1\n",
    "        yield data\n",
    "\n",
    "# Set the paths to the .npy files\n",
    "file_paths = glob.glob(os.path.join('dataset', '*.npy'))\n",
    "\n",
    "# Create a TensorFlow dataset using dataset.from_generator\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: data_generator(file_paths),\n",
    "    output_types=(tf.float32,tf.int8)\n",
    "    #output_signature=tf.TensorSpec(shape=(116504, 784), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "dataset.shuffle(buffer_size=1000000)\n",
    "\n",
    "c = 0\n",
    "for data, labels in dataset:\n",
    "    c += 1\n",
    "    # Process the data\n",
    "    print(data.shape, labels.shape)\n",
    "    print(labels)\n",
    "    #print(data[1])\n",
    "    if c == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   5  16   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  83 248 253 101   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  50 252 255 184  33\n",
      "  18  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 106 255 192 255 255 254  74   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 101 255\n",
      " 246 252 231 255  80   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  14 114 136 190 253 214 224 229 255 177 136 136 136\n",
      " 136 136 136 136 136 136 128 112  97  82  67  48   2   0   0  93 255 243\n",
      " 239 242 238 238 240 247 238 238 238 238 238 238 238 238 238 238 249 255\n",
      " 255 255 255 255  94   0   0  22 251 125   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   9  24  39  84 255  87   0   0   0\n",
      " 181 248 191 159  68  51  51  34  34  23  17  11   0   0   0   0   0   0\n",
      "   0   6  24  43 107 255  61   0   0   0  32 133 208 255 255 255 255 255\n",
      " 255 255 255 255 255 255 238 238 227 225 243 255 255 255 255 233  21   0\n",
      "   0   0   0   0  14 174 215 227 236 244 255 255 255 255 188 125 136 137\n",
      " 153 151 133 115  97  79  58   6   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  12  23  34   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "#data = np.load('dataset\\\\aircraft_carrier.npy')\n",
    "#print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6uUjN-WL2Y9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_test\\\\aircraft_carrier.npy', 'dataset_test\\\\airplane.npy', 'dataset_test\\\\alarm_clock.npy', 'dataset_test\\\\ambulance.npy', 'dataset_test\\\\angel.npy', 'dataset_test\\\\animal_migration.npy']\n",
      "6\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11132\\711908681.py\", line 14, in load_and_process  *\n        data = np.load(file_path)\n    File \"C:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 407, in load  **\n        fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n\n    TypeError: expected str, bytes or os.PathLike object, not Tensor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [123]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#x_train, y_train, x_test, y_test, x_val, y_val, class_names = load_data('dataset')\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mload_data_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad np data time: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m(s)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(end \u001b[38;5;241m-\u001b[39m start))\n",
      "Input \u001b[1;32mIn [122]\u001b[0m, in \u001b[0;36mload_data_batch\u001b[1;34m(root, vfold_ratio_test, vfold_ratio_val, file_batch_size)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Map the file_dataset to the load_and_process function\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m data_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfile_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_and_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_dataset\u001b[38;5;241m.\u001b[39mcardinality()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Concatenate the data_dataset into a single combined dataset\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2202\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[0;32m   2200\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2201\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2202\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2204\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[0;32m   2205\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2206\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2209\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2210\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5400\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m   5399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[1;32m-> 5400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5402\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5404\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   5406\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[0;32m   5407\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5408\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5411\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m   5412\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2611\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[38;5;66;03m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m placeholder_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_capture_func_lib  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileq2ai1ymk.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__load_and_process\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\numpy\\lib\\npyio.py:407\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    405\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    408\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11132\\711908681.py\", line 14, in load_and_process  *\n        data = np.load(file_path)\n    File \"C:\\ProgramData\\anaconda3\\envs\\NuEdgeWise_env\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 407, in load  **\n        fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n\n    TypeError: expected str, bytes or os.PathLike object, not Tensor\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "start = time.time()\n",
    "#x_train, y_train, x_test, y_test, x_val, y_val, class_names = load_data('dataset')\n",
    "load_data_batch('dataset_test')\n",
    "end = time.time()\n",
    "print('Load np data time: {}(s)'.format(end - start))\n",
    "\n",
    "\n",
    "\n",
    "#num_classes = len(class_names)\n",
    "#print(\"Total Classes: {}.\".format(num_classes))\n",
    "#print(\"The number of train data: {}. test data: {}. validation data: {}.\".format(len(x_train), len(x_test), len(x_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNZmQvBWBBHE"
   },
   "source": [
    "Show some random data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "KfpDaHRkyMQC",
    "outputId": "0f070893-98d5-42fa-b77d-f0a1d57210f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zebra\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_train))\n",
    "plt.imshow(x_train[idx].reshape(28,28)) \n",
    "print(class_names[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n",
      "zebra\n"
     ]
    }
   ],
   "source": [
    "print(int(y_train[idx].item()))\n",
    "print(class_names[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "1\n",
      "5\n",
      "8\n",
      "4\n",
      "3\n",
      "2\n",
      "9\n",
      "10\n",
      "\n",
      "Testing Dataset:\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create the original dataset\n",
    "dataset = tf.data.Dataset.range(1, 11)  # Dataset with elements [1, 2, 3, ..., 10]\n",
    "\n",
    "# Shuffle the dataset\n",
    "shuffled_dataset = dataset.shuffle(buffer_size=10, reshuffle_each_iteration=False)\n",
    "\n",
    "# Calculate the split sizes\n",
    "total_size = 10\n",
    "train_size = int(0.8 * total_size)  # 80% of the data for training\n",
    "test_size = total_size - train_size  # Remaining 20% for testing\n",
    "\n",
    "# Convert the shuffled dataset into an iterator\n",
    "iterator = iter(shuffled_dataset)\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: iterator, tf.int64).take(train_size)\n",
    "test_dataset = tf.data.Dataset.from_generator(lambda: iterator, tf.int64).take(test_size)\n",
    "\n",
    "# Print the elements in each dataset\n",
    "print(\"Training Dataset:\")\n",
    "for element in train_dataset:\n",
    "    print(element.numpy())  # Print the values\n",
    "\n",
    "print(\"\\nTesting Dataset:\")\n",
    "for element in test_dataset:\n",
    "    print(element.numpy())  # Print the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "6\n",
      "7\n",
      "9\n",
      "5\n",
      "3\n",
      "4\n",
      "10\n",
      "1\n",
      "\n",
      "Testing Dataset:\n",
      "2\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create the original dataset\n",
    "dataset = tf.data.Dataset.range(1, 11)  # Dataset with elements [1, 2, 3, ..., 10]\n",
    "\n",
    "# Shuffle the dataset\n",
    "shuffled_dataset = dataset.shuffle(buffer_size=10, reshuffle_each_iteration=False)\n",
    "\n",
    "# Calculate the split sizes\n",
    "total_size = 10\n",
    "train_size = int(0.8 * total_size)  # 80% of the data for training\n",
    "test_size = total_size - train_size  # Remaining 20% for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset = shuffled_dataset.take(train_size)\n",
    "test_dataset = shuffled_dataset.skip(train_size).take(test_size)\n",
    "\n",
    "# Print the elements in each dataset\n",
    "print(\"Training Dataset:\")\n",
    "for element in train_dataset:\n",
    "    print(element.numpy())  # Print the values\n",
    "\n",
    "print(\"\\nTesting Dataset:\")\n",
    "for element in test_dataset:\n",
    "    print(element.numpy())  # Print the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8InHz5NBFrV"
   },
   "source": [
    "# Preprocess the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2GHUq7D2r9e"
   },
   "outputs": [],
   "source": [
    "# Get the train data length\n",
    "len_train_data = x_train.shape[0]\n",
    "# Reshape and normalize\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
    "x_val = x_val.reshape(x_val.shape[0], image_size, image_size, 1).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "x_val /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96600, 28, 28, 1) (96600, 345)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to TF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(len_train_data).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rL6XAb4hBMSc"
   },
   "source": [
    "# The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "uYUVV2wf2z8H",
    "outputId": "521cf96e-3039-411e-d14e-5aaca559b518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 14, 14, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 7, 7, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               73856     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 345)               44505     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141,657\n",
      "Trainable params: 141,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "# Define model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Convolution2D(16, (3, 3),\n",
    "                        padding='same',\n",
    "                        input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='tanh'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax')) \n",
    "# Train model\n",
    "adam = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['top_k_categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YRSRkOyBP1P"
   },
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "7OMEJ7kF3lsP",
    "outputId": "4d9a46ad-2ed1-4b4f-c1ec-687997025034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "378/378 [==============================] - ETA: 0s - loss: 4.5299 - top_k_categorical_accuracy: 0.3002\n",
      "Epoch 1: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 9s 7ms/step - loss: 4.5299 - top_k_categorical_accuracy: 0.3002 - val_loss: 3.7932 - val_top_k_categorical_accuracy: 0.4712\n",
      "Epoch 2/10\n",
      "371/378 [============================>.] - ETA: 0s - loss: 3.4289 - top_k_categorical_accuracy: 0.5465\n",
      "Epoch 2: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 3.4246 - top_k_categorical_accuracy: 0.5474 - val_loss: 3.1984 - val_top_k_categorical_accuracy: 0.5904\n",
      "Epoch 3/10\n",
      "364/378 [===========================>..] - ETA: 0s - loss: 2.9868 - top_k_categorical_accuracy: 0.6279\n",
      "Epoch 3: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 2.9814 - top_k_categorical_accuracy: 0.6290 - val_loss: 2.9160 - val_top_k_categorical_accuracy: 0.6386\n",
      "Epoch 4/10\n",
      "364/378 [===========================>..] - ETA: 0s - loss: 2.7203 - top_k_categorical_accuracy: 0.6764\n",
      "Epoch 4: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 2.7188 - top_k_categorical_accuracy: 0.6767 - val_loss: 2.7311 - val_top_k_categorical_accuracy: 0.6736\n",
      "Epoch 5/10\n",
      "367/378 [============================>.] - ETA: 0s - loss: 2.5328 - top_k_categorical_accuracy: 0.7080\n",
      "Epoch 5: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 2.5317 - top_k_categorical_accuracy: 0.7081 - val_loss: 2.6011 - val_top_k_categorical_accuracy: 0.6962\n",
      "Epoch 6/10\n",
      "365/378 [===========================>..] - ETA: 0s - loss: 2.3940 - top_k_categorical_accuracy: 0.7300\n",
      "Epoch 6: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 2.3934 - top_k_categorical_accuracy: 0.7299 - val_loss: 2.5168 - val_top_k_categorical_accuracy: 0.7091\n",
      "Epoch 7/10\n",
      "376/378 [============================>.] - ETA: 0s - loss: 2.2829 - top_k_categorical_accuracy: 0.7476\n",
      "Epoch 7: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 2.2821 - top_k_categorical_accuracy: 0.7477 - val_loss: 2.4512 - val_top_k_categorical_accuracy: 0.7201\n",
      "Epoch 8/10\n",
      "376/378 [============================>.] - ETA: 0s - loss: 2.1937 - top_k_categorical_accuracy: 0.7621\n",
      "Epoch 8: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 2.1933 - top_k_categorical_accuracy: 0.7622 - val_loss: 2.3961 - val_top_k_categorical_accuracy: 0.7279\n",
      "Epoch 9/10\n",
      "372/378 [============================>.] - ETA: 0s - loss: 2.1114 - top_k_categorical_accuracy: 0.7748\n",
      "Epoch 9: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 2.1113 - top_k_categorical_accuracy: 0.7749 - val_loss: 2.3672 - val_top_k_categorical_accuracy: 0.7319\n",
      "Epoch 10/10\n",
      "365/378 [===========================>..] - ETA: 0s - loss: 2.0434 - top_k_categorical_accuracy: 0.7850\n",
      "Epoch 10: saving model to workspace\\345_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: workspace\\345_test\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 2.0462 - top_k_categorical_accuracy: 0.7846 - val_loss: 2.3529 - val_top_k_categorical_accuracy: 0.7367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x138682212e0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"workspace/345_test\"\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1)\n",
    "\n",
    "#model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=10, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2KztY7qEn9_"
   },
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ssaZczS7DxeA",
    "outputId": "63f7726d-205e-4cf7-9540-0c3d379e54e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuarcy: 73.63%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xBM_w0VBbNr"
   },
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "nH3JfoiYHdpk",
    "outputId": "ca2ed216-7069-4caf-b72a-784a11da8553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alarm_clock', 'bread', 't-shirt', 'butterfly', 'bird']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndBEPqNBFPKBCF/HA/wNSuG+7tunptgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3c10abc88>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_test))\n",
    "img = x_test[idx]\n",
    "plt.imshow(img.squeeze()) \n",
    "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "ind = (-pred).argsort()[:5]\n",
    "latex = [class_names[x] for x in ind]\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPp5D82YBhM-"
   },
   "source": [
    "# Store the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NoFI1msFYpCN"
   },
   "outputs": [],
   "source": [
    "with open('class_names.txt', 'w') as file_handler:\n",
    "    for item in class_names:\n",
    "        file_handler.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfJ6dpaDBpRx"
   },
   "source": [
    "# Install TensorFlowJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "colab_type": "code",
    "id": "hJJDfp9mY9Xh",
    "outputId": "5f1b0500-99ca-4935-89da-d2359bb5c29b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/fd/39f5e1709a543cdce74f2ff6423d70800dbb785494ff66765464feeb67a5/tensorflowjs-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: tensorflow==1.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.8.0)\n",
      "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
      "Collecting keras==2.1.4 (from tensorflowjs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/45/a273fe3f8fe931a11da34fba1cb74013cfc70dcf93e5d8d329c951dc44c5/Keras-2.1.4-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% || 327kB 6.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py==2.7.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.7.1)\n",
      "Collecting numpy==1.14.1 (from tensorflowjs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/7d/348c5d8d44443656e76285aa97b828b6dbd9c10e5b9c0f7f98eff0ff70e4/numpy-1.14.1-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% || 12.2MB 3.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub==0.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (0.6.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (3.5.2.post1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (1.12.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (0.31.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0->tensorflowjs) (1.8.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.4->tensorflowjs) (0.19.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.4->tensorflowjs) (3.12)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8.0->tensorflowjs) (39.2.0)\n",
      "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0->tensorflowjs) (1.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0->tensorflowjs) (2.6.11)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0->tensorflowjs) (0.14.1)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0->tensorflowjs) (0.9999999)\n",
      "Installing collected packages: numpy, keras, tensorflowjs\n",
      "  Found existing installation: numpy 1.14.3\n",
      "    Uninstalling numpy-1.14.3:\n",
      "      Successfully uninstalled numpy-1.14.3\n",
      "  Found existing installation: Keras 2.1.6\n",
      "    Uninstalling Keras-2.1.6:\n",
      "      Successfully uninstalled Keras-2.1.6\n",
      "Successfully installed keras-2.1.4 numpy-1.14.1 tensorflowjs-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-oBl0ZKVB00d"
   },
   "source": [
    "# Save and Convert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVICB3TbZGb2"
   },
   "outputs": [],
   "source": [
    "model.save('keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "id": "bTWWlGdWZOvs",
    "outputId": "98724960-128d-4ecc-cdb0-460f7c06536e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory model: File exists\n",
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!mkdir model\n",
    "!tensorflowjs_converter --input_format keras keras.h5 model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKYxE2MEB6LV"
   },
   "source": [
    "# Zip and Download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "865-t79uaB63"
   },
   "outputs": [],
   "source": [
    "!cp class_names.txt model/class_names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "id": "GLC-MzW8ZXTa",
    "outputId": "402d4e6c-da44-4815-fe0a-34a90e886e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model/ (stored 0%)\n",
      "  adding: model/group5-shard1of1 (deflated 7%)\n",
      "  adding: model/model.json (deflated 82%)\n",
      "  adding: model/group2-shard1of1 (deflated 7%)\n",
      "  adding: model/group3-shard1of1 (deflated 7%)\n",
      "  adding: model/class_names.txt (deflated 41%)\n",
      "  adding: model/group1-shard1of1 (stored 0%)\n",
      "  adding: model/group4-shard1of1 (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r model.zip model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vfPR03xZZeD"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('model.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Sketcher.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
